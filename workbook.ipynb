{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c08ed86",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>\n",
    "    <b> Assignment Two: </b> [insert cool title here]\n",
    "</h1>\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "By Katelyn Abille, Daniel Hwang, Weihao Lin, and Andy Tran\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e33a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from collections import defaultdict, Counter\n",
    "import mido\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0394416e",
   "metadata": {},
   "source": [
    "## Task One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef953e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymbolicMusicGeneratorUnconditional:\n",
    "    def __init__(self):\n",
    "        self.trigram_model = defaultdict(Counter)\n",
    "        self.tempo_transitions = defaultdict(list)\n",
    "        self.note_durations = defaultdict(list)\n",
    "        self.velocity_patterns = defaultdict(list)\n",
    "        self.time_signatures = []\n",
    "        self.tempos = []\n",
    "        \n",
    "    def extract_musical_events(self, midi_file_path):\n",
    "        \"\"\"Extract musical events from a MIDI file including timing information\"\"\"\n",
    "        try:\n",
    "            mid = MidiFile(midi_file_path)\n",
    "            events = []\n",
    "            current_tempo = 500000  # Default tempo (120 BPM)\n",
    "            current_time = 0\n",
    "            \n",
    "            # Track active notes for duration calculation\n",
    "            active_notes = {}\n",
    "            \n",
    "            for track in mid.tracks:\n",
    "                track_time = 0\n",
    "                for msg in track:\n",
    "                    track_time += msg.time\n",
    "                    current_time = track_time\n",
    "                    \n",
    "                    if msg.type == 'set_tempo':\n",
    "                        current_tempo = msg.tempo\n",
    "                        events.append(('tempo', msg.tempo, current_time))\n",
    "                        \n",
    "                    elif msg.type == 'time_signature':\n",
    "                        events.append(('time_sig', f\"{msg.numerator}/{msg.denominator}\", current_time))\n",
    "                        \n",
    "                    elif msg.type == 'note_on' and msg.velocity > 0:\n",
    "                        note_key = (msg.channel, msg.note)\n",
    "                        active_notes[note_key] = {\n",
    "                            'start_time': current_time,\n",
    "                            'velocity': msg.velocity,\n",
    "                            'tempo': current_tempo\n",
    "                        }\n",
    "                        events.append(('note_on', msg.note, current_time, msg.velocity, current_tempo))\n",
    "                        \n",
    "                    elif msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0):\n",
    "                        note_key = (msg.channel, msg.note)\n",
    "                        if note_key in active_notes:\n",
    "                            note_info = active_notes[note_key]\n",
    "                            duration = current_time - note_info['start_time']\n",
    "                            events.append(('note_off', msg.note, current_time, duration, note_info['velocity']))\n",
    "                            del active_notes[note_key]\n",
    "            \n",
    "            return events\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {midi_file_path}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def create_symbolic_representation(self, events):\n",
    "        \"\"\"Convert events to symbolic representation for Markov chain\"\"\"\n",
    "        symbols = []\n",
    "        prev_time = 0\n",
    "        \n",
    "        # Filter and sort note events\n",
    "        note_events = [(e[2], e) for e in events if e[0] == 'note_on']\n",
    "        note_events.sort()  # Sort by time\n",
    "        \n",
    "        for time_pos, event in note_events:\n",
    "            note = event[1]\n",
    "            velocity = event[3]\n",
    "            tempo = event[4]\n",
    "            \n",
    "            # Calculate time delta from previous note\n",
    "            time_delta = max(0, time_pos - prev_time)\n",
    "            prev_time = time_pos\n",
    "            \n",
    "            # Quantize timing to musical values (in ticks)\n",
    "            if time_delta < 120:\n",
    "                timing = \"T1\"  # Very short\n",
    "            elif time_delta < 240:\n",
    "                timing = \"T2\"  # Eighth note\n",
    "            elif time_delta < 480:\n",
    "                timing = \"T3\"  # Quarter note\n",
    "            elif time_delta < 960:\n",
    "                timing = \"T4\"  # Half note\n",
    "            else:\n",
    "                timing = \"T5\"  # Whole note or longer\n",
    "            \n",
    "            # Quantize velocity more musically\n",
    "            if velocity < 40:\n",
    "                vel_level = \"pp\"  # pianissimo\n",
    "            elif velocity < 70:\n",
    "                vel_level = \"mp\"  # mezzo-piano  \n",
    "            elif velocity < 90:\n",
    "                vel_level = \"mf\"  # mezzo-forte\n",
    "            elif velocity < 110:\n",
    "                vel_level = \"f\"   # forte\n",
    "            else:\n",
    "                vel_level = \"ff\"  # fortissimo\n",
    "            \n",
    "            # Use pitch classes and octaves for better musical coherence\n",
    "            pitch_class = note % 12\n",
    "            octave = note // 12\n",
    "            \n",
    "            # Create more musical symbol\n",
    "            symbol = f\"P{pitch_class}_O{octave}_{vel_level}_{timing}\"\n",
    "            symbols.append(symbol)\n",
    "                \n",
    "        return symbols\n",
    "    \n",
    "    def build_trigram_model(self, symbols):\n",
    "        \"\"\"Build trigram Markov chain from symbols\"\"\"\n",
    "        for i in range(len(symbols) - 2):\n",
    "            trigram_key = (symbols[i], symbols[i + 1])\n",
    "            next_symbol = symbols[i + 2]\n",
    "            self.trigram_model[trigram_key][next_symbol] += 1\n",
    "    \n",
    "    def train_on_dataset(self, dataset_path, max_files=50):\n",
    "        \"\"\"Train the model on MIDI files from the dataset\"\"\"\n",
    "        print(\"Scanning for MIDI files...\")\n",
    "        midi_files = []\n",
    "        \n",
    "        # Recursively find all .mid files\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.mid', '.midi')):\n",
    "                    midi_files.append(os.path.join(root, file))\n",
    "        \n",
    "        print(f\"Found {len(midi_files)} MIDI files\")\n",
    "        \n",
    "        # Limit the number of files to process for reasonable training time\n",
    "        if len(midi_files) > max_files:\n",
    "            midi_files = random.sample(midi_files, max_files)\n",
    "            print(f\"Processing {max_files} randomly selected files\")\n",
    "        \n",
    "        processed_count = 0\n",
    "        total_notes = 0\n",
    "        octave_distribution = defaultdict(int)\n",
    "        \n",
    "        for midi_file in midi_files:\n",
    "            print(f\"Processing: {os.path.basename(midi_file)} ({processed_count + 1}/{len(midi_files)})\")\n",
    "            \n",
    "            events = self.extract_musical_events(midi_file)\n",
    "            if events:\n",
    "                symbols = self.create_symbolic_representation(events)\n",
    "                if len(symbols) > 10:  # Only use files with sufficient content\n",
    "                    self.build_trigram_model(symbols)\n",
    "                    \n",
    "                    # Debug: track octave distribution\n",
    "                    for symbol in symbols:\n",
    "                        if symbol.startswith('P'):\n",
    "                            try:\n",
    "                                parts = symbol.split('_')\n",
    "                                octave = int(parts[1][1:])\n",
    "                                octave_distribution[octave] += 1\n",
    "                                total_notes += 1\n",
    "                            except:\n",
    "                                pass\n",
    "                    \n",
    "                    # Store additional musical information\n",
    "                    tempos = [e[1] for e in events if e[0] == 'tempo']\n",
    "                    if tempos:\n",
    "                        self.tempos.extend(tempos)\n",
    "                        \n",
    "                processed_count += 1\n",
    "        \n",
    "        print(f\"Training completed on {processed_count} files\")\n",
    "        print(f\"Learned {len(self.trigram_model)} trigram patterns\")\n",
    "        print(f\"Total notes processed: {total_notes}\")\n",
    "        print(\"Octave distribution in training data:\")\n",
    "        for octave in sorted(octave_distribution.keys()):\n",
    "            percentage = (octave_distribution[octave] / total_notes) * 100\n",
    "            print(f\"  Octave {octave}: {octave_distribution[octave]} notes ({percentage:.1f}%)\")\n",
    "    \n",
    "    def generate_sequence(self, length=200, seed=None):\n",
    "        \"\"\"Generate a new sequence using the trigram model\"\"\"\n",
    "        if len(self.trigram_model) == 0:\n",
    "            raise ValueError(\"Model not trained yet!\")\n",
    "        \n",
    "        # Start with a random trigram or use seed\n",
    "        if seed and len(seed) >= 2:\n",
    "            current_bigram = (seed[0], seed[1])\n",
    "        else:\n",
    "            current_bigram = random.choice(list(self.trigram_model.keys()))\n",
    "        \n",
    "        sequence = list(current_bigram)\n",
    "        \n",
    "        # Track musical context for better generation\n",
    "        last_pitch_class = None\n",
    "        last_octave = None\n",
    "        octave_bias = 0  # Bias to encourage higher octaves\n",
    "        \n",
    "        for i in range(length - 2):\n",
    "            if current_bigram in self.trigram_model:\n",
    "                # Choose next symbol based on probability distribution\n",
    "                next_symbols = self.trigram_model[current_bigram]\n",
    "                total_count = sum(next_symbols.values())\n",
    "                \n",
    "                if total_count > 0:\n",
    "                    # Create weighted list for better selection\n",
    "                    weighted_choices = []\n",
    "                    for symbol, count in next_symbols.items():\n",
    "                        # Add some musical intelligence - prefer steps and skips\n",
    "                        weight = count\n",
    "                        if symbol.startswith('P') and last_pitch_class is not None:\n",
    "                            try:\n",
    "                                parts = symbol.split('_')\n",
    "                                pitch_class = int(parts[0][1:])\n",
    "                                octave = int(parts[1][1:])\n",
    "                                \n",
    "                                # Strongly favor higher octaves\n",
    "                                if octave >= 5:\n",
    "                                    weight = int(weight * 2.0)\n",
    "                                elif octave >= 4:\n",
    "                                    weight = int(weight * 1.5)\n",
    "                                elif octave <= 2:\n",
    "                                    weight = max(1, int(weight * 0.3))  # Heavily discourage low octaves\n",
    "                                \n",
    "                                # Slightly favor melodic intervals (steps and small skips)\n",
    "                                interval = abs(pitch_class - last_pitch_class)\n",
    "                                if interval <= 2 or interval >= 10:  # Steps (including octave wrapping)\n",
    "                                    weight = int(weight * 1.2)\n",
    "                                elif interval <= 4 or interval >= 8:  # Small skips\n",
    "                                    weight = int(weight * 1.1)\n",
    "                                \n",
    "                                # Favor staying in similar octave range\n",
    "                                if abs(octave - last_octave) <= 1:\n",
    "                                    weight = int(weight * 1.1)\n",
    "                                    \n",
    "                                last_pitch_class = pitch_class\n",
    "                                last_octave = octave\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        weighted_choices.extend([symbol] * max(1, weight))\n",
    "                    \n",
    "                    if weighted_choices:\n",
    "                        next_symbol = random.choice(weighted_choices)\n",
    "                        sequence.append(next_symbol)\n",
    "                        current_bigram = (current_bigram[1], next_symbol)\n",
    "                    else:\n",
    "                        # Fallback\n",
    "                        current_bigram = random.choice(list(self.trigram_model.keys()))\n",
    "                        sequence.extend(current_bigram)\n",
    "                else:\n",
    "                    # Fallback to random trigram\n",
    "                    current_bigram = random.choice(list(self.trigram_model.keys()))\n",
    "                    sequence.extend(current_bigram)\n",
    "            else:\n",
    "                # Start new random trigram\n",
    "                current_bigram = random.choice(list(self.trigram_model.keys()))\n",
    "                sequence.extend(current_bigram)\n",
    "        \n",
    "        return sequence\n",
    "    \n",
    "    def sequence_to_midi(self, sequence, output_path=\"generated_music.mid\"):\n",
    "        \"\"\"Convert generated sequence back to MIDI file with proper timing\"\"\"\n",
    "        mid = MidiFile(ticks_per_beat=480)\n",
    "        track = MidiTrack()\n",
    "        mid.tracks.append(track)\n",
    "        \n",
    "        # Set default tempo\n",
    "        default_tempo = 500000 if not self.tempos else random.choice(self.tempos)\n",
    "        track.append(mido.MetaMessage('set_tempo', tempo=int(default_tempo), time=0))\n",
    "        \n",
    "        # Add time signature\n",
    "        track.append(mido.MetaMessage('time_signature', numerator=4, denominator=4, time=0))\n",
    "        \n",
    "        # Store events with absolute timing first\n",
    "        events = []\n",
    "        current_time = 0\n",
    "        \n",
    "        for i, symbol in enumerate(sequence):\n",
    "            if symbol.startswith('P'):\n",
    "                try:\n",
    "                    parts = symbol.split('_')\n",
    "                    if len(parts) >= 4:\n",
    "                        pitch_class = int(parts[0][1:])\n",
    "                        octave = int(parts[1][1:])\n",
    "                        vel_level = parts[2]\n",
    "                        timing = parts[3]\n",
    "                        \n",
    "                        # Constrain octave to reasonable range\n",
    "                        octave = max(3, min(7, octave))\n",
    "                        note = (octave * 12) + pitch_class\n",
    "                        \n",
    "                        # Ensure note is in valid MIDI range (0-127)\n",
    "                        note = max(0, min(127, note))\n",
    "                        \n",
    "                        # Convert velocity level to MIDI velocity\n",
    "                        velocity_map = {\n",
    "                            \"pp\": 35, \"mp\": 55, \"mf\": 75, \"f\": 95, \"ff\": 115\n",
    "                        }\n",
    "                        velocity = velocity_map.get(vel_level, 70)\n",
    "                        \n",
    "                        # Convert timing to ticks - make them shorter for better playback\n",
    "                        timing_map = {\n",
    "                            \"T1\": 240,   # Eighth note\n",
    "                            \"T2\": 480,   # Quarter note  \n",
    "                            \"T3\": 720,   # Dotted quarter\n",
    "                            \"T4\": 960,   # Half note\n",
    "                            \"T5\": 1440   # Dotted half\n",
    "                        }\n",
    "                        duration = timing_map.get(timing, 480)\n",
    "                        \n",
    "                        # Add note on event\n",
    "                        events.append(('note_on', current_time, note, velocity))\n",
    "                        # Add note off event\n",
    "                        events.append(('note_off', current_time + int(duration * 0.9), note, 0))\n",
    "                        \n",
    "                        # Advance time for next note (with some overlap allowed)\n",
    "                        current_time += int(duration * 0.7)  # 70% spacing allows overlap\n",
    "                        \n",
    "                except (ValueError, IndexError):\n",
    "                    current_time += 480  # Default quarter note spacing\n",
    "            else:\n",
    "                current_time += 240  # Shorter default for non-notes\n",
    "        \n",
    "        # Sort events by time\n",
    "        events.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # Convert to MIDI messages with delta times\n",
    "        last_time = 0\n",
    "        for event in events:\n",
    "            event_type, abs_time, note, velocity = event\n",
    "            delta_time = abs_time - last_time\n",
    "            \n",
    "            if event_type == 'note_on':\n",
    "                track.append(mido.Message('note_on', channel=0, note=note, \n",
    "                                        velocity=velocity, time=delta_time))\n",
    "            else:  # note_off\n",
    "                track.append(mido.Message('note_off', channel=0, note=note, \n",
    "                                        velocity=64, time=delta_time))\n",
    "            \n",
    "            last_time = abs_time\n",
    "        \n",
    "        # Add a final rest\n",
    "        track.append(mido.Message('note_off', channel=0, note=60, velocity=0, time=480))\n",
    "        \n",
    "        mid.save(output_path)\n",
    "        print(f\"Generated MIDI saved as: {output_path}\")\n",
    "        print(f\"Total events: {len(events)}\")\n",
    "        print(f\"Duration: ~{current_time / 480:.1f} beats\")\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"Save the trained model\"\"\"\n",
    "        model_data = {\n",
    "            'trigram_model': dict(self.trigram_model),\n",
    "            'tempos': self.tempos,\n",
    "            'time_signatures': self.time_signatures\n",
    "        }\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "        print(f\"Model saved to: {filepath}\")\n",
    "    \n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"Load a trained model\"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        self.trigram_model = defaultdict(Counter, model_data['trigram_model'])\n",
    "        self.tempos = model_data['tempos']\n",
    "        self.time_signatures = model_data['time_signatures']\n",
    "        print(f\"Model loaded from: {filepath}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd0858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generator\n",
    "generator = SymbolicMusicGeneratorUnconditional()\n",
    "\n",
    "# Train on your dataset\n",
    "dataset_path = \"maestro-v3.0.0\"\n",
    "generator.train_on_dataset(dataset_path, max_files=300)  # Adjust max_files as needed\n",
    "\n",
    "# Save the trained model\n",
    "generator.save_model(\"music_model.pkl\")\n",
    "\n",
    "# Generate new music\n",
    "print(\"\\nGenerating new music...\")\n",
    "sequence = generator.generate_sequence(length=500)\n",
    "generator.sequence_to_midi(sequence, \"task1.mid\")\n",
    "print(\"Music generation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7547b14",
   "metadata": {},
   "source": [
    "## Task Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymbolicMusicGeneratorConditional:\n",
    "    def __init__(self):\n",
    "        self.trigram_model = defaultdict(Counter)\n",
    "        self.harmony_model = defaultdict(Counter)  # For harmonization\n",
    "        self.melody_model = defaultdict(Counter)   # For melody generation\n",
    "        self.chord_progressions = defaultdict(Counter)  # For chord-based generation\n",
    "        self.tempo_transitions = defaultdict(list)\n",
    "        self.note_durations = defaultdict(list)\n",
    "        self.velocity_patterns = defaultdict(list)\n",
    "        self.time_signatures = []\n",
    "        self.tempos = []\n",
    "        \n",
    "    def extract_musical_events(self, midi_file_path):\n",
    "        \"\"\"Extract musical events from a MIDI file including timing information\"\"\"\n",
    "        try:\n",
    "            mid = MidiFile(midi_file_path)\n",
    "            events = []\n",
    "            current_tempo = 500000  # Default tempo (120 BPM)\n",
    "            current_time = 0\n",
    "            \n",
    "            # Track active notes for duration calculation and harmony analysis\n",
    "            active_notes = {}\n",
    "            simultaneous_notes = defaultdict(list)  # For harmony extraction\n",
    "            \n",
    "            for track in mid.tracks:\n",
    "                track_time = 0\n",
    "                for msg in track:\n",
    "                    track_time += msg.time\n",
    "                    current_time = track_time\n",
    "                    \n",
    "                    if msg.type == 'set_tempo':\n",
    "                        current_tempo = msg.tempo\n",
    "                        events.append(('tempo', msg.tempo, current_time))\n",
    "                        \n",
    "                    elif msg.type == 'time_signature':\n",
    "                        events.append(('time_sig', f\"{msg.numerator}/{msg.denominator}\", current_time))\n",
    "                        \n",
    "                    elif msg.type == 'note_on' and msg.velocity > 0:\n",
    "                        note_key = (msg.channel, msg.note)\n",
    "                        active_notes[note_key] = {\n",
    "                            'start_time': current_time,\n",
    "                            'velocity': msg.velocity,\n",
    "                            'tempo': current_tempo\n",
    "                        }\n",
    "                        # Group notes by time windows for harmony analysis\n",
    "                        time_window = current_time // 240  # 240 ticks = eighth note window\n",
    "                        simultaneous_notes[time_window].append(msg.note)\n",
    "                        \n",
    "                        events.append(('note_on', msg.note, current_time, msg.velocity, current_tempo))\n",
    "                        \n",
    "                    elif msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0):\n",
    "                        note_key = (msg.channel, msg.note)\n",
    "                        if note_key in active_notes:\n",
    "                            note_info = active_notes[note_key]\n",
    "                            duration = current_time - note_info['start_time']\n",
    "                            events.append(('note_off', msg.note, current_time, duration, note_info['velocity']))\n",
    "                            del active_notes[note_key]\n",
    "            \n",
    "            # Store harmony information for conditional generation\n",
    "            self._extract_harmonies(simultaneous_notes)\n",
    "            \n",
    "            return events\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {midi_file_path}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _extract_harmonies(self, simultaneous_notes):\n",
    "        \"\"\"Extract harmony patterns from simultaneous notes\"\"\"\n",
    "        for time_window, notes in simultaneous_notes.items():\n",
    "            if len(notes) >= 2:  # At least 2 notes for harmony\n",
    "                # Sort notes and create chord representation\n",
    "                sorted_notes = sorted(set(notes))  # Remove duplicates and sort\n",
    "                if len(sorted_notes) >= 2:\n",
    "                    # Create melody-harmony pairs (lowest note as melody, others as harmony)\n",
    "                    melody_note = sorted_notes[0] % 12  # Pitch class of lowest note\n",
    "                    harmony_notes = [n % 12 for n in sorted_notes[1:]]  # Pitch classes of harmony\n",
    "                    \n",
    "                    # Store melody -> harmony mapping\n",
    "                    harmony_key = f\"M{melody_note}\"\n",
    "                    harmony_value = \"_\".join([f\"H{h}\" for h in sorted(harmony_notes)])\n",
    "                    self.harmony_model[harmony_key][harmony_value] += 1\n",
    "                    \n",
    "                    # Store harmony -> melody mapping (for melody generation from chords)\n",
    "                    if len(harmony_notes) >= 2:  # At least 2 harmony notes\n",
    "                        chord_key = \"_\".join([f\"C{h}\" for h in sorted(harmony_notes)])\n",
    "                        melody_value = f\"M{melody_note}\"\n",
    "                        self.melody_model[chord_key][melody_value] += 1\n",
    "    \n",
    "    def _notes_to_chord_symbol(self, notes):\n",
    "        \"\"\"Convert a list of notes to a simplified chord symbol\"\"\"\n",
    "        if not notes:\n",
    "            return \"REST\"\n",
    "        \n",
    "        # Convert to pitch classes and sort\n",
    "        pitch_classes = sorted(set([n % 12 for n in notes]))\n",
    "        \n",
    "        if len(pitch_classes) == 1:\n",
    "            return f\"SINGLE_{pitch_classes[0]}\"\n",
    "        elif len(pitch_classes) == 2:\n",
    "            interval = (pitch_classes[1] - pitch_classes[0]) % 12\n",
    "            return f\"INT_{pitch_classes[0]}_{interval}\"\n",
    "        else:\n",
    "            # Simple chord classification\n",
    "            root = pitch_classes[0]\n",
    "            intervals = [(pc - root) % 12 for pc in pitch_classes[1:]]\n",
    "            intervals_str = \"_\".join(map(str, sorted(intervals)))\n",
    "            return f\"CHORD_{root}_{intervals_str}\"\n",
    "    def create_symbolic_representation(self, events):\n",
    "        \"\"\"Convert events to symbolic representation for Markov chain\"\"\"\n",
    "        symbols = []\n",
    "        prev_time = 0\n",
    "        \n",
    "        # Filter and sort note events\n",
    "        note_events = [(e[2], e) for e in events if e[0] == 'note_on']\n",
    "        note_events.sort()  # Sort by time\n",
    "        \n",
    "        for time_pos, event in note_events:\n",
    "            note = event[1]\n",
    "            velocity = event[3]\n",
    "            tempo = event[4]\n",
    "            \n",
    "            # Calculate time delta from previous note\n",
    "            time_delta = max(0, time_pos - prev_time)\n",
    "            prev_time = time_pos\n",
    "            \n",
    "            # Quantize timing to musical values (in ticks)\n",
    "            if time_delta < 120:\n",
    "                timing = \"T1\"  # Very short\n",
    "            elif time_delta < 240:\n",
    "                timing = \"T2\"  # Eighth note\n",
    "            elif time_delta < 480:\n",
    "                timing = \"T3\"  # Quarter note\n",
    "            elif time_delta < 960:\n",
    "                timing = \"T4\"  # Half note\n",
    "            else:\n",
    "                timing = \"T5\"  # Whole note or longer\n",
    "            \n",
    "            # Quantize velocity more musically\n",
    "            if velocity < 40:\n",
    "                vel_level = \"pp\"  # pianissimo\n",
    "            elif velocity < 70:\n",
    "                vel_level = \"mp\"  # mezzo-piano  \n",
    "            elif velocity < 90:\n",
    "                vel_level = \"mf\"  # mezzo-forte\n",
    "            elif velocity < 110:\n",
    "                vel_level = \"f\"   # forte\n",
    "            else:\n",
    "                vel_level = \"ff\"  # fortissimo\n",
    "            \n",
    "            # Use pitch classes and octaves for better musical coherence\n",
    "            pitch_class = note % 12\n",
    "            octave = note // 12\n",
    "            \n",
    "            # Create more musical symbol\n",
    "            symbol = f\"P{pitch_class}_O{octave}_{vel_level}_{timing}\"\n",
    "            symbols.append(symbol)\n",
    "                \n",
    "        return symbols\n",
    "    \n",
    "    def build_trigram_model(self, symbols):\n",
    "        \"\"\"Build trigram Markov chain from symbols\"\"\"\n",
    "        for i in range(len(symbols) - 2):\n",
    "            trigram_key = (symbols[i], symbols[i + 1])\n",
    "            next_symbol = symbols[i + 2]\n",
    "            self.trigram_model[trigram_key][next_symbol] += 1\n",
    "    \n",
    "    def train_on_dataset(self, dataset_path, max_files=50):\n",
    "        \"\"\"Train the model on MIDI files from the dataset\"\"\"\n",
    "        print(\"Scanning for MIDI files...\")\n",
    "        midi_files = []\n",
    "        \n",
    "        # Recursively find all .mid files\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.mid', '.midi')):\n",
    "                    midi_files.append(os.path.join(root, file))\n",
    "        \n",
    "        print(f\"Found {len(midi_files)} MIDI files\")\n",
    "        \n",
    "        # Limit the number of files to process for reasonable training time\n",
    "        if len(midi_files) > max_files:\n",
    "            midi_files = random.sample(midi_files, max_files)\n",
    "            print(f\"Processing {max_files} randomly selected files\")\n",
    "        \n",
    "        processed_count = 0\n",
    "        total_notes = 0\n",
    "        octave_distribution = defaultdict(int)\n",
    "        \n",
    "        for midi_file in midi_files:\n",
    "            print(f\"Processing: {os.path.basename(midi_file)} ({processed_count + 1}/{len(midi_files)})\")\n",
    "            \n",
    "            events = self.extract_musical_events(midi_file)\n",
    "            if events:\n",
    "                symbols = self.create_symbolic_representation(events)\n",
    "                if len(symbols) > 10:  # Only use files with sufficient content\n",
    "                    self.build_trigram_model(symbols)\n",
    "                    \n",
    "                    # Debug: track octave distribution\n",
    "                    for symbol in symbols:\n",
    "                        if symbol.startswith('P'):\n",
    "                            try:\n",
    "                                parts = symbol.split('_')\n",
    "                                octave = int(parts[1][1:])\n",
    "                                octave_distribution[octave] += 1\n",
    "                                total_notes += 1\n",
    "                            except:\n",
    "                                pass\n",
    "                    \n",
    "                    # Store additional musical information\n",
    "                    tempos = [e[1] for e in events if e[0] == 'tempo']\n",
    "                    if tempos:\n",
    "                        self.tempos.extend(tempos)\n",
    "                        \n",
    "                processed_count += 1\n",
    "        \n",
    "        print(f\"Training completed on {processed_count} files\")\n",
    "        print(f\"Learned {len(self.trigram_model)} trigram patterns\")\n",
    "        print(f\"Total notes processed: {total_notes}\")\n",
    "        print(\"Octave distribution in training data:\")\n",
    "        for octave in sorted(octave_distribution.keys()):\n",
    "            percentage = (octave_distribution[octave] / total_notes) * 100\n",
    "            print(f\"  Octave {octave}: {octave_distribution[octave]} notes ({percentage:.1f}%)\")\n",
    "    \n",
    "    def generate_sequence(self, length=200, seed=None):\n",
    "        \"\"\"Generate a new sequence using the trigram model\"\"\"\n",
    "        if len(self.trigram_model) == 0:\n",
    "            raise ValueError(\"Model not trained yet!\")\n",
    "        \n",
    "        # Start with a random trigram or use seed\n",
    "        if seed and len(seed) >= 2:\n",
    "            current_bigram = (seed[0], seed[1])\n",
    "        else:\n",
    "            current_bigram = random.choice(list(self.trigram_model.keys()))\n",
    "        \n",
    "        sequence = list(current_bigram)\n",
    "        \n",
    "        # Track musical context for better generation\n",
    "        last_pitch_class = None\n",
    "        last_octave = None\n",
    "        octave_bias = 0  # Bias to encourage higher octaves\n",
    "        \n",
    "        for i in range(length - 2):\n",
    "            if current_bigram in self.trigram_model:\n",
    "                # Choose next symbol based on probability distribution\n",
    "                next_symbols = self.trigram_model[current_bigram]\n",
    "                total_count = sum(next_symbols.values())\n",
    "                \n",
    "                if total_count > 0:\n",
    "                    # Create weighted list for better selection\n",
    "                    weighted_choices = []\n",
    "                    for symbol, count in next_symbols.items():\n",
    "                        # Add some musical intelligence - prefer steps and skips\n",
    "                        weight = count\n",
    "                        if symbol.startswith('P') and last_pitch_class is not None:\n",
    "                            try:\n",
    "                                parts = symbol.split('_')\n",
    "                                pitch_class = int(parts[0][1:])\n",
    "                                octave = int(parts[1][1:])\n",
    "                                \n",
    "                                # Strongly favor higher octaves\n",
    "                                if octave >= 5:\n",
    "                                    weight = int(weight * 2.0)\n",
    "                                elif octave >= 4:\n",
    "                                    weight = int(weight * 1.5)\n",
    "                                elif octave <= 2:\n",
    "                                    weight = max(1, int(weight * 0.3))  # Heavily discourage low octaves\n",
    "                                \n",
    "                                # Slightly favor melodic intervals (steps and small skips)\n",
    "                                interval = abs(pitch_class - last_pitch_class)\n",
    "                                if interval <= 2 or interval >= 10:  # Steps (including octave wrapping)\n",
    "                                    weight = int(weight * 1.2)\n",
    "                                elif interval <= 4 or interval >= 8:  # Small skips\n",
    "                                    weight = int(weight * 1.1)\n",
    "                                \n",
    "                                # Favor staying in similar octave range\n",
    "                                if abs(octave - last_octave) <= 1:\n",
    "                                    weight = int(weight * 1.1)\n",
    "                                    \n",
    "                                last_pitch_class = pitch_class\n",
    "                                last_octave = octave\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        weighted_choices.extend([symbol] * max(1, weight))\n",
    "                    \n",
    "                    if weighted_choices:\n",
    "                        next_symbol = random.choice(weighted_choices)\n",
    "                        sequence.append(next_symbol)\n",
    "                        current_bigram = (current_bigram[1], next_symbol)\n",
    "                    else:\n",
    "                        # Fallback\n",
    "                        current_bigram = random.choice(list(self.trigram_model.keys()))\n",
    "                        sequence.extend(current_bigram)\n",
    "                else:\n",
    "                    # Fallback to random trigram\n",
    "                    current_bigram = random.choice(list(self.trigram_model.keys()))\n",
    "                    sequence.extend(current_bigram)\n",
    "            else:\n",
    "                # Start new random trigram\n",
    "                current_bigram = random.choice(list(self.trigram_model.keys()))\n",
    "                sequence.extend(current_bigram)\n",
    "        \n",
    "        return sequence\n",
    "    \n",
    "    def generate_harmonization(self, melody_notes, length=None):\n",
    "        \"\"\"Generate harmonization for a given melody\"\"\"\n",
    "        if len(self.harmony_model) == 0:\n",
    "            raise ValueError(\"Harmony model not trained yet!\")\n",
    "        \n",
    "        harmonized_sequence = []\n",
    "        \n",
    "        # If melody_notes is a list of MIDI note numbers, convert to symbols\n",
    "        if isinstance(melody_notes[0], int):\n",
    "            melody_symbols = []\n",
    "            for note in melody_notes:\n",
    "                pitch_class = note % 12\n",
    "                octave = note // 12\n",
    "                # Use default velocity and timing for input melody\n",
    "                symbol = f\"P{pitch_class}_O{octave}_mf_T3\"\n",
    "                melody_symbols.append(symbol)\n",
    "            melody_notes = melody_symbols\n",
    "        \n",
    "        # Extend melody to reach target length if specified\n",
    "        if length is not None:\n",
    "            if len(melody_notes) < length:\n",
    "                # Repeat the melody pattern to reach desired length\n",
    "                extended_melody = []\n",
    "                for i in range(length):\n",
    "                    extended_melody.append(melody_notes[i % len(melody_notes)])\n",
    "                melody_notes = extended_melody\n",
    "            else:\n",
    "                # If melody is already longer than target, truncate it\n",
    "                melody_notes = melody_notes[:length]\n",
    "        \n",
    "        for melody_symbol in melody_notes:\n",
    "            # Add the original melody note\n",
    "            harmonized_sequence.append(melody_symbol)\n",
    "            \n",
    "            # Extract pitch class from melody note\n",
    "            if melody_symbol.startswith('P'):\n",
    "                try:\n",
    "                    parts = melody_symbol.split('_')\n",
    "                    pitch_class = int(parts[0][1:])\n",
    "                    octave = int(parts[1][1:])\n",
    "                    \n",
    "                    melody_key = f\"M{pitch_class}\"\n",
    "                    \n",
    "                    if melody_key in self.harmony_model:\n",
    "                        # Choose harmony based on learned patterns\n",
    "                        harmony_options = self.harmony_model[melody_key]\n",
    "                        total_count = sum(harmony_options.values())\n",
    "                        \n",
    "                        if total_count > 0:\n",
    "                            # Weighted random selection\n",
    "                            weighted_choices = []\n",
    "                            for harmony_pattern, count in harmony_options.items():\n",
    "                                weighted_choices.extend([harmony_pattern] * count)\n",
    "                            \n",
    "                            chosen_harmony = random.choice(weighted_choices)\n",
    "                            \n",
    "                            # Convert harmony pattern back to note symbols\n",
    "                            harmony_notes = chosen_harmony.split('_')\n",
    "                            for harmony_note in harmony_notes:\n",
    "                                if harmony_note.startswith('H'):\n",
    "                                    harmony_pitch = int(harmony_note[1:])\n",
    "                                    # Place harmony in appropriate octave (usually higher)\n",
    "                                    harmony_octave = octave if harmony_pitch > pitch_class else octave + 1\n",
    "                                    harmony_octave = min(7, harmony_octave)  # Keep in range\n",
    "                                    \n",
    "                                    harmony_symbol = f\"P{harmony_pitch}_O{harmony_octave}_mp_T3\"\n",
    "                                    harmonized_sequence.append(harmony_symbol)\n",
    "                \n",
    "                except (ValueError, IndexError):\n",
    "                    pass  # Skip if parsing fails\n",
    "        \n",
    "        return harmonized_sequence\n",
    "\n",
    "    def generate_melody_from_chords(self, chord_progression, length=100):\n",
    "        \"\"\"Generate melody that follows a chord progression\"\"\"\n",
    "        if len(self.melody_model) == 0:\n",
    "            raise ValueError(\"Melody model not trained yet!\")\n",
    "        \n",
    "        melody_sequence = []\n",
    "        \n",
    "        # Convert chord progression to our internal format if needed\n",
    "        if isinstance(chord_progression[0], list):\n",
    "            # chord_progression is list of lists of MIDI notes\n",
    "            chord_symbols = []\n",
    "            for chord_notes in chord_progression:\n",
    "                pitch_classes = sorted([n % 12 for n in chord_notes])\n",
    "                chord_key = \"_\".join([f\"C{pc}\" for pc in pitch_classes])\n",
    "                chord_symbols.append(chord_key)\n",
    "            chord_progression = chord_symbols\n",
    "        \n",
    "        notes_per_chord = max(1, length // len(chord_progression))\n",
    "        \n",
    "        for chord_symbol in chord_progression:\n",
    "            # Generate melody notes for this chord\n",
    "            for _ in range(notes_per_chord):\n",
    "                if chord_symbol in self.melody_model:\n",
    "                    melody_options = self.melody_model[chord_symbol]\n",
    "                    total_count = sum(melody_options.values())\n",
    "                    \n",
    "                    if total_count > 0:\n",
    "                        # Weighted random selection\n",
    "                        weighted_choices = []\n",
    "                        for melody_pattern, count in melody_options.items():\n",
    "                            weighted_choices.extend([melody_pattern] * count)\n",
    "                        \n",
    "                        chosen_melody = random.choice(weighted_choices)\n",
    "                        \n",
    "                        # Convert back to full symbol\n",
    "                        if chosen_melody.startswith('M'):\n",
    "                            pitch_class = int(chosen_melody[1:])\n",
    "                            octave = random.choice([4, 5, 6])  # Melody range\n",
    "                            velocity = random.choice(['mp', 'mf', 'f'])\n",
    "                            timing = random.choice(['T2', 'T3', 'T4'])\n",
    "                            \n",
    "                            melody_symbol = f\"P{pitch_class}_O{octave}_{velocity}_{timing}\"\n",
    "                            melody_sequence.append(melody_symbol)\n",
    "                else:\n",
    "                    # Fallback: generate from unconditional model\n",
    "                    if len(self.trigram_model) > 0:\n",
    "                        current_bigram = random.choice(list(self.trigram_model.keys()))\n",
    "                        melody_sequence.extend(current_bigram)\n",
    "        \n",
    "        return melody_sequence[:length]\n",
    "    \n",
    "    def generate_style_transfer(self, input_melody, target_style_velocity=\"f\", target_style_timing=\"T2\"):\n",
    "        \"\"\"Transfer the style of an input melody (change velocity/timing patterns)\"\"\"\n",
    "        styled_sequence = []\n",
    "        \n",
    "        # If input is MIDI notes, convert first\n",
    "        if isinstance(input_melody[0], int):\n",
    "            input_symbols = []\n",
    "            for note in input_melody:\n",
    "                pitch_class = note % 12\n",
    "                octave = note // 12\n",
    "                symbol = f\"P{pitch_class}_O{octave}_mf_T3\"\n",
    "                input_symbols.append(symbol)\n",
    "            input_melody = input_symbols\n",
    "        \n",
    "        for symbol in input_melody:\n",
    "            if symbol.startswith('P'):\n",
    "                try:\n",
    "                    parts = symbol.split('_')\n",
    "                    pitch_part = parts[0]  # P{pitch_class}\n",
    "                    octave_part = parts[1]  # O{octave}\n",
    "                    \n",
    "                    # Apply style transfer\n",
    "                    new_symbol = f\"{pitch_part}_{octave_part}_{target_style_velocity}_{target_style_timing}\"\n",
    "                    styled_sequence.append(new_symbol)\n",
    "                    \n",
    "                except (ValueError, IndexError):\n",
    "                    styled_sequence.append(symbol)  # Keep original if parsing fails\n",
    "            else:\n",
    "                styled_sequence.append(symbol)\n",
    "        \n",
    "        return styled_sequence\n",
    "    \n",
    "    def sequence_to_midi(self, sequence, output_path=\"generated_music.mid\"):\n",
    "        \"\"\"Convert generated sequence back to MIDI file with proper timing\"\"\"\n",
    "        mid = MidiFile(ticks_per_beat=480)\n",
    "        track = MidiTrack()\n",
    "        mid.tracks.append(track)\n",
    "        \n",
    "        # Set default tempo\n",
    "        default_tempo = 500000 if not self.tempos else random.choice(self.tempos)\n",
    "        track.append(mido.MetaMessage('set_tempo', tempo=int(default_tempo), time=0))\n",
    "        \n",
    "        # Add time signature\n",
    "        track.append(mido.MetaMessage('time_signature', numerator=4, denominator=4, time=0))\n",
    "        \n",
    "        # Store events with absolute timing first\n",
    "        events = []\n",
    "        current_time = 0\n",
    "        \n",
    "        for i, symbol in enumerate(sequence):\n",
    "            if symbol.startswith('P'):\n",
    "                try:\n",
    "                    parts = symbol.split('_')\n",
    "                    if len(parts) >= 4:\n",
    "                        pitch_class = int(parts[0][1:])\n",
    "                        octave = int(parts[1][1:])\n",
    "                        vel_level = parts[2]\n",
    "                        timing = parts[3]\n",
    "                        \n",
    "                        # Constrain octave to reasonable range\n",
    "                        octave = max(3, min(7, octave))\n",
    "                        note = (octave * 12) + pitch_class\n",
    "                        \n",
    "                        # Ensure note is in valid MIDI range (0-127)\n",
    "                        note = max(0, min(127, note))\n",
    "                        \n",
    "                        # Convert velocity level to MIDI velocity\n",
    "                        velocity_map = {\n",
    "                            \"pp\": 35, \"mp\": 55, \"mf\": 75, \"f\": 95, \"ff\": 115\n",
    "                        }\n",
    "                        velocity = velocity_map.get(vel_level, 70)\n",
    "                        \n",
    "                        # Convert timing to ticks - make them shorter for better playback\n",
    "                        timing_map = {\n",
    "                            \"T1\": 240,   # Eighth note\n",
    "                            \"T2\": 480,   # Quarter note  \n",
    "                            \"T3\": 720,   # Dotted quarter\n",
    "                            \"T4\": 960,   # Half note\n",
    "                            \"T5\": 1440   # Dotted half\n",
    "                        }\n",
    "                        duration = timing_map.get(timing, 480)\n",
    "                        \n",
    "                        # Add note on event\n",
    "                        events.append(('note_on', current_time, note, velocity))\n",
    "                        # Add note off event\n",
    "                        events.append(('note_off', current_time + int(duration * 0.9), note, 0))\n",
    "                        \n",
    "                        # Advance time for next note (with some overlap allowed)\n",
    "                        current_time += int(duration * 0.7)  # 70% spacing allows overlap\n",
    "                        \n",
    "                except (ValueError, IndexError):\n",
    "                    current_time += 480  # Default quarter note spacing\n",
    "            else:\n",
    "                current_time += 240  # Shorter default for non-notes\n",
    "        \n",
    "        # Sort events by time\n",
    "        events.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # Convert to MIDI messages with delta times\n",
    "        last_time = 0\n",
    "        for event in events:\n",
    "            event_type, abs_time, note, velocity = event\n",
    "            delta_time = abs_time - last_time\n",
    "            \n",
    "            if event_type == 'note_on':\n",
    "                track.append(mido.Message('note_on', channel=0, note=note, \n",
    "                                        velocity=velocity, time=delta_time))\n",
    "            else:  # note_off\n",
    "                track.append(mido.Message('note_off', channel=0, note=note, \n",
    "                                        velocity=64, time=delta_time))\n",
    "            \n",
    "            last_time = abs_time\n",
    "        \n",
    "        # Add a final rest\n",
    "        track.append(mido.Message('note_off', channel=0, note=60, velocity=0, time=480))\n",
    "        \n",
    "        mid.save(output_path)\n",
    "        print(f\"Generated MIDI saved as: {output_path}\")\n",
    "        print(f\"Total events: {len(events)}\")\n",
    "        print(f\"Duration: ~{current_time / 480:.1f} beats\")\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"Save the trained model\"\"\"\n",
    "        model_data = {\n",
    "            'trigram_model': dict(self.trigram_model),\n",
    "            'harmony_model': dict(self.harmony_model),\n",
    "            'melody_model': dict(self.melody_model),\n",
    "            'chord_progressions': dict(self.chord_progressions),\n",
    "            'tempos': self.tempos,\n",
    "            'time_signatures': self.time_signatures\n",
    "        }\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "        print(f\"Model saved to: {filepath}\")\n",
    "    \n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"Load a trained model\"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        self.trigram_model = defaultdict(Counter, model_data['trigram_model'])\n",
    "        self.harmony_model = defaultdict(Counter, model_data.get('harmony_model', {}))\n",
    "        self.melody_model = defaultdict(Counter, model_data.get('melody_model', {}))\n",
    "        self.chord_progressions = defaultdict(Counter, model_data.get('chord_progressions', {}))\n",
    "        self.tempos = model_data['tempos']\n",
    "        self.time_signatures = model_data['time_signatures']\n",
    "        print(f\"Model loaded from: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec0a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and generate\n",
    "generator = SymbolicMusicGeneratorConditional()\n",
    "generator.train_on_dataset(\"maestro-v3.0.0\", max_files=500)\n",
    "\n",
    "chord_progression = [\n",
    "        [60, 64, 67],  # C major (C-E-G)\n",
    "        [65, 69, 72],  # F major (F-A-C)\n",
    "        [67, 71, 74],  # G major (G-B-D)  \n",
    "        [60, 64, 67]   # C major (C-E-G)\n",
    "    ]\n",
    "\n",
    "chord_melody = generator.generate_melody_from_chords(chord_progression, length=500)\n",
    "energetic_chord = generator.generate_style_transfer(chord_melody, target_style_velocity=\"ff\", target_style_timing=\"T1\")\n",
    "generator.sequence_to_midi(energetic_chord, \"task2.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7828173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HARMONY USAGE\n",
    "# melody = [60, 64, 67, 65]  # C4, E4, G4, F4\n",
    "# harmonized = generator.generate_harmonization(melody, 500)\n",
    "# generator.sequence_to_midi(harmonized, \"task2.mid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse153",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
